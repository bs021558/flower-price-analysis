name: Airflow Scheduler Sync

on:
  push:
    branches:
      - main
    paths:
      - 'dags/**'
      
jobs:
  sync_scheduler:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v2

      - name: Create SSH Key
        run: |
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > $HOME/gcp-docker.pem
          chmod 600 $HOME/gcp-docker.pem
      - name: Create SSH directory
        run: |
          mkdir -p ~/.ssh

      - name: Add known host
        run: |
          ssh-keyscan 34.64.119.159 >> ~/.ssh/known_hosts

      - name: Get DAGs Directory
        run: |
          DAGS_DIR="${{ github.workspace }}/dags"
          REMOTE_DIR="~/learn-airflow/dags"
          
          # Your logic to get the specific file or files
          FILE_TO_COPY=$(find "$DAGS_DIR" -name '*.py' -type f)

          #chmod
          ssh -i $HOME/gcp-docker.pem es344299@34.64.119.159 "find $REMOTE_DIR -type d -exec chmod 755 {} \; && find $REMOTE_DIR -type f -exec chmod 644 {} \;"

          # Copy the file to the remote directory
          scp -v -i $HOME/gcp-docker.pem $FILE_TO_COPY es344299@34.64.119.159:$REMOTE_DIR/
          
          echo "Copied DAGs to Airflow server"
